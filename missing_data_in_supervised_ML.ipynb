{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Missing data in supervised ML</center>\n",
    "### <center>Andras Zsom</center>\n",
    "<center>Lead Data Scientist and  Adjunct Lecturer in Data Science</center>\n",
    "<center>Center for Computation and Visualization</center>\n",
    "<center>Brown University</center>\n",
    "<center>Providence, RI, USA</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## About me\n",
    "- Born and raised in Hungary\n",
    "- Astrophysics PhD at MPIA, Heidelberg, Germany\n",
    "- Postdoctoral researcher at MIT (still in astrophysics at the time)\n",
    "- Started at Brown in December 2015 as a Data Scientist\n",
    "- Promoted to Lead Data Scientist in 2017\n",
    "- Adjunct Lecturer in Data Science this semester\n",
    "   - Teaching the course *DATA1030: Hands-on data science* to the DS master students at Brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Science at Brown\n",
    "- Center for Computation and Visualization\n",
    "- Institutional Data group\n",
    "   - Data-driven decision support and predictive modeling for Brownâ€™s administrative units\n",
    "   - Academic research on data-intensive projects\n",
    "- **OPEN POSITION** - more on this later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this workshop, you will be able to\n",
    "- Describe the three main types of missingness patterns\n",
    "- Evaluate simple approaches for handling missing values\n",
    "- Apply multivariate imputation\n",
    "- Apply XGBoost to a dataset with missing values\n",
    "- Apply the reduced-features model (also called the pattern submodel approach)\n",
    "- Decide which approach is best for your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Before we start, a few words on our dataset: kaggle house price\n",
    "- good for educational purposes\n",
    "   - messy data that requires quite a bit of preprocessing\n",
    "   - a nice mixture of continuous, ordinal, and categorical features, each feature type has missing values\n",
    "- lots of excellent kernels on kaggle\n",
    "   - check them out [here]()\n",
    "- dataset and description available in repo\n",
    "   - let's take a look!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Learning Objectives</font>\n",
    "\n",
    "<font color='LIGHTGRAY'>By the end of this workshop, you will be able to</font>\n",
    "- **Describe the three main types of missingness patterns**\n",
    "- <font color='LIGHTGRAY'>Evaluate simple approaches for handling missing values</font>\n",
    "- <font color='LIGHTGRAY'>Apply multivariate imputation</font>\n",
    "- <font color='LIGHTGRAY'>Apply XGBoost to a dataset with missing values</font>\n",
    "- <font color='LIGHTGRAY'>Apply the reduced-features model (also called the pattern submodel approach)</font>\n",
    "- <font color='LIGHTGRAY'>Decide which approach is best for your dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Missing values often occur in datasets\n",
    "- survey data: not everyone answers all the questions\n",
    "- medical data: not all tests/treatments/etc are performed on all patients\n",
    "- sensor can be offline or malfunctioning\n",
    "- customer data: not every user uses all features of an app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Missing values are an issue for multiple reasons\n",
    "\n",
    "#### Concenptual reason\n",
    "- missing values can introduce biases\n",
    "    - bias: the samples (the data points) are not representative of the underlying distribution/population\n",
    "    - any conclusion drawn from a biased dataset is also biased.\n",
    "    - rich people tend to not fill out survey questions about their salaries and the mean salary estimated from survey data tend to be lower than true value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Practical reason\n",
    "- missing values (NaN, NA, inf) are incompatible with sklearn\n",
    "   - all values in an array need to be numerical otherwise sklearn will throw a *ValueError*\n",
    "- there are a few supervised ML techniques that work with missing values (e.g., XGBoost, CatBoost)\n",
    "   - we will cover those later today"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Missing data patterns\n",
    "\n",
    "- **MCAR** - Missing Complete At Random\n",
    "   - some people skip some survey questions by accident\n",
    "- **MAR** - Missing At Random\n",
    "   - males are less likely to fill out a survey on depression\n",
    "   - this has nothing to do with their level of depression after accounting for maleness\n",
    "- **MNAR** - Missing Not At Random\n",
    "   - depressed people are less likely to fill out a survey on depression due to their level of depression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MCAR test\n",
    "\n",
    "- MCAR can be diagnosed with a statistical test ([Little, 1988](https://www.tandfonline.com/doi/abs/10.1080/01621459.1988.10478722))\n",
    "   - python implementation available in the [pymice](https://github.com/RianneSchouten/pymice) package or in the skipped slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# from the pymice package \n",
    "# https://github.com/RianneSchouten/pymice\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as ma\n",
    "import scipy.stats as st\n",
    "\n",
    "def checks_input_mcar_tests(data):\n",
    "    \"\"\" Checks whether the input parameter of class McarTests is correct\n",
    "            Parameters\n",
    "            ----------\n",
    "            data:\n",
    "                The input of McarTests specified as 'data'\n",
    "            Returns\n",
    "            -------\n",
    "            bool\n",
    "                True if input is correct\n",
    "            \"\"\"\n",
    "\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        print(\"Error: Data should be a Pandas DataFrame\")\n",
    "        return False\n",
    "\n",
    "    if not any(data.dtypes.values == np.float):\n",
    "        if not any(data.dtypes.values == np.int):\n",
    "            print(\"Error: Dataset cannot contain other value types than floats and/or integers\")\n",
    "            return False\n",
    "\n",
    "    if not data.isnull().values.any():\n",
    "        print(\"Error: No NaN's in given data\")\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def mcar_test(data):\n",
    "    \"\"\" Implementation of Little's MCAR test\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: Pandas DataFrame\n",
    "        An incomplete dataset with samples as index and variables as columns\n",
    "    Returns\n",
    "    -------\n",
    "    p_value: Float\n",
    "        This value is the outcome of a chi-square statistical test, testing whether the null hypothesis\n",
    "        'the missingness mechanism of the incomplete dataset is MCAR' can be rejected.\n",
    "    \"\"\"\n",
    "\n",
    "    if not checks_input_mcar_tests(data):\n",
    "        raise Exception(\"Input not correct\")\n",
    "\n",
    "    dataset = data.copy()\n",
    "    vars = dataset.dtypes.index.values\n",
    "    n_var = dataset.shape[1]\n",
    "\n",
    "    # mean and covariance estimates\n",
    "    # ideally, this is done with a maximum likelihood estimator\n",
    "    gmean = dataset.mean()\n",
    "    gcov = dataset.cov()\n",
    "\n",
    "    # set up missing data patterns\n",
    "    r = 1 * dataset.isnull()\n",
    "    mdp = np.dot(r, list(map(lambda x: ma.pow(2, x), range(n_var))))\n",
    "    sorted_mdp = sorted(np.unique(mdp))\n",
    "    n_pat = len(sorted_mdp)\n",
    "    correct_mdp = list(map(lambda x: sorted_mdp.index(x), mdp))\n",
    "    dataset['mdp'] = pd.Series(correct_mdp, index=dataset.index)\n",
    "\n",
    "    # calculate statistic and df\n",
    "    pj = 0\n",
    "    d2 = 0\n",
    "    for i in range(n_pat):\n",
    "        dataset_temp = dataset.loc[dataset['mdp'] == i, vars]\n",
    "        select_vars = ~dataset_temp.isnull().any()\n",
    "        pj += np.sum(select_vars)\n",
    "        select_vars = vars[select_vars]\n",
    "        means = dataset_temp[select_vars].mean() - gmean[select_vars]\n",
    "        select_cov = gcov.loc[select_vars, select_vars]\n",
    "        mj = len(dataset_temp)\n",
    "        parta = np.dot(means.T, np.linalg.solve(select_cov, np.identity(select_cov.shape[1])))\n",
    "        d2 += mj * (np.dot(parta, means))\n",
    "\n",
    "    df = pj - n_var\n",
    "\n",
    "    # perform test and save output\n",
    "    p_value = 1 - st.chi2.cdf(d2, df)\n",
    "\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Takeaway\n",
    "- it can be challenging to infer the missingness pattern from an incomplete dataset\n",
    "   - There is a statistical test to diagnose MCAR\n",
    "   - MAR and MNAR are difficult/impossible to diagnose to the best of my knowledge\n",
    "- multiple patterns can be present in the data\n",
    "   - even worse, multiple patterns can be present in one feature!\n",
    "   - missing values in a feature can occur due to a mix of MCAR, MAR, MNAR \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Learning Objectives</font>\n",
    "\n",
    "<font color='LIGHTGRAY'>By the end of this workshop, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>Describe the three main types of missingness patterns</font>\n",
    "- **Evaluate simple approaches for handling missing values**\n",
    "- <font color='LIGHTGRAY'>Apply multivariate imputation</font>\n",
    "- <font color='LIGHTGRAY'>Apply XGBoost to a dataset with missing values</font>\n",
    "- <font color='LIGHTGRAY'>Apply the reduced-features model (also called the pattern submodel approach)</font>\n",
    "- <font color='LIGHTGRAY'>Decide which approach is best for your dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple approaches for handling missing values\n",
    "- 1) categorical/ordinal features: treat missing values as another category\n",
    "    - missing values in categorical/ordinal features are not a big deal\n",
    "- 2) continuous features: this is the tough part\n",
    "    - sklearn's SimpleImputer\n",
    "- 3) exclude points or features with missing values\n",
    "    - might be OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1a) Missing values in a categorical feature\n",
    "- YAY - this is not an issue at all!\n",
    "- Categorical feature needs to be one-hot encoded anyway\n",
    "- Just replace the missing values with 'NA' or 'missing' and treat it as a separate category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1b) Missing values in a ordinal feature\n",
    "- this can be a bit trickier but usually fine\n",
    "- Ordinal encoder is applied to ordinal features\n",
    "    - where does 'NA' or 'missing' fit into the order of the categories?\n",
    "    - usually first or last\n",
    "- if you can figure this out, you are golden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 79)\n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Let's load the data\n",
    "df = pd.read_csv('data/train.csv')\n",
    "# drop the ID\n",
    "df.drop(columns=['Id'],inplace=True)\n",
    "\n",
    "# the target variable\n",
    "y = df['SalePrice']\n",
    "df.drop(columns=['SalePrice'],inplace=True)\n",
    "# the unprocessed feature matrix\n",
    "X = df.values\n",
    "print(X.shape)\n",
    "# the feature names\n",
    "ftrs = df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  MSSubClass MSZoning LotFrontage LotArea Street Alley LotShape LandContour  \\\n",
      "0         20       RL          90   11694   Pave   NaN      Reg         Lvl   \n",
      "1         20       RL          60    6600   Pave   NaN      Reg         Lvl   \n",
      "2         30       RL          80   13360   Pave  Grvl      IR1         HLS   \n",
      "3         20       RL         NaN   13265   Pave   NaN      IR1         Lvl   \n",
      "4         20       RL         118   13704   Pave   NaN      IR1         Lvl   \n",
      "\n",
      "  Utilities LotConfig  ... ScreenPorch PoolArea PoolQC Fence MiscFeature  \\\n",
      "0    AllPub    Inside  ...         260        0    NaN   NaN         NaN   \n",
      "1    AllPub    Inside  ...           0        0    NaN   NaN         NaN   \n",
      "2    AllPub    Inside  ...           0        0    NaN   NaN         NaN   \n",
      "3    AllPub   CulDSac  ...           0        0    NaN   NaN         NaN   \n",
      "4    AllPub    Corner  ...           0        0    NaN   NaN         NaN   \n",
      "\n",
      "  MiscVal MoSold YrSold SaleType SaleCondition  \n",
      "0       0      7   2007      New       Partial  \n",
      "1       0      8   2009       WD        Normal  \n",
      "2       0      8   2009       WD        Normal  \n",
      "3       0      7   2008       WD        Normal  \n",
      "4       0      1   2006       WD        Normal  \n",
      "\n",
      "[5 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "# let's split to train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train = pd.DataFrame(data=X_train,columns=ftrs)\n",
    "X_test = pd.DataFrame(data=X_test,columns=ftrs)\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# collect the various features\n",
    "cat_ftrs = ['MSZoning','Street','Alley','LandContour','LotConfig','Neighborhood','Condition1','Condition2',\\\n",
    "            'BldgType','HouseStyle','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Foundation',\\\n",
    "           'Heating','CentralAir','Electrical','GarageType','PavedDrive','MiscFeature','SaleType','SaleCondition']\n",
    "ordinal_ftrs = ['LotShape','Utilities','LandSlope','ExterQual','ExterCond','BsmtQual','BsmtCond','BsmtExposure',\\\n",
    "               'BsmtFinType1','BsmtFinType2','HeatingQC','KitchenQual','Functional','FireplaceQu','GarageFinish',\\\n",
    "               'GarageQual','GarageCond','PoolQC','Fence']\n",
    "ordinal_cats = [['Reg','IR1','IR2','IR3'],['AllPub','NoSewr','NoSeWa','ELO'],['Gtl','Mod','Sev'],\\\n",
    "               ['Po','Fa','TA','Gd','Ex'],['Po','Fa','TA','Gd','Ex'],['NA','Po','Fa','TA','Gd','Ex'],\\\n",
    "               ['NA','Po','Fa','TA','Gd','Ex'],['NA','No','Mn','Av','Gd'],['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],\\\n",
    "               ['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ'],['Po','Fa','TA','Gd','Ex'],['Po','Fa','TA','Gd','Ex'],\\\n",
    "               ['Sal','Sev','Maj2','Maj1','Mod','Min2','Min1','Typ'],['NA','Po','Fa','TA','Gd','Ex'],\\\n",
    "               ['NA','Unf','RFn','Fin'],['NA','Po','Fa','TA','Gd','Ex'],['NA','Po','Fa','TA','Gd','Ex'],\n",
    "               ['NA','Fa','TA','Gd','Ex'],['NA','MnWw','GdWo','MnPrv','GdPrv']]\n",
    "num_ftrs = ['MSSubClass','LotFrontage','LotArea','OverallQual','OverallCond','YearBuilt','YearRemodAdd',\\\n",
    "             'MasVnrArea','BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','1stFlrSF','2ndFlrSF',\\\n",
    "             'LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr',\\\n",
    "             'KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageYrBlt','GarageCars','GarageArea','WoodDeckSF',\\\n",
    "             'OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','MiscVal','MoSold','YrSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# preprocess with pipeline and columntransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# one-hot encoder\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant',fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'))])\n",
    "\n",
    "# ordinal encoder\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer2', SimpleImputer(strategy='constant',fill_value='NA')),\n",
    "    ('ordinal', OrdinalEncoder(categories = ordinal_cats))])\n",
    "\n",
    "# standard scaler\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# collect the transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_ftrs),\n",
    "        ('cat', categorical_transformer, cat_ftrs),\n",
    "        ('ord', ordinal_transformer, ordinal_ftrs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 226)\n",
      "(292, 226)\n",
      "(1460, 226)\n"
     ]
    }
   ],
   "source": [
    "# fit_transform the data\n",
    "X_prep = preprocessor.fit_transform(X_train)\n",
    "# little hacky, but collect feature names\n",
    "feature_names = preprocessor.transformers_[0][-1] + \\\n",
    "                list(preprocessor.named_transformers_['cat'][1].get_feature_names(cat_ftrs)) + \\\n",
    "                preprocessor.transformers_[2][-1]\n",
    "\n",
    "df_prep = pd.DataFrame(data=X_prep,columns=feature_names)\n",
    "df_prep['SalePrice'] = y_train\n",
    "\n",
    "print(df_prep.shape)\n",
    "\n",
    "df_prep.to_csv('data/house_price_prep.csv',index=False)\n",
    "\n",
    "df_test = preprocessor.transform(X_test)\n",
    "df_test = pd.DataFrame(data=df_test,columns = feature_names)\n",
    "df_test['SalePrice'] = y_test\n",
    "\n",
    "print(df_test.shape)\n",
    "\n",
    "df = pd.concat([df_prep,df_test],axis=0)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Let's take a closer look at our missing values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value of the mcar test: 0.0\n",
      "data dimensions: (1168, 226)\n",
      "fraction of missing values in features:\n",
      "LotFrontage    0.181507\n",
      "MasVnrArea     0.005137\n",
      "GarageYrBlt    0.049658\n",
      "SalePrice      0.206336\n",
      "dtype: float64\n",
      "fraction of points with missing values: 0.3895547945205479\n"
     ]
    }
   ],
   "source": [
    "print('p value of the mcar test:',mcar_test(df))\n",
    "print('data dimensions:',df_prep.shape)\n",
    "perc_missing_per_ftr = df_prep.isnull().sum(axis=0)/df_prep.shape[0]\n",
    "print('fraction of missing values in features:')\n",
    "print(perc_missing_per_ftr[perc_missing_per_ftr > 0])\n",
    "frac_missing = sum(df_prep.isnull().sum(axis=1)!=0)/df_prep.shape[0]\n",
    "print('fraction of points with missing values:',frac_missing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2) Continuous features: mean or median imputation\n",
    "- Imputation means you infer the missing values from the known part of the data\n",
    "- sklearn's SimpleImputer can do mean and median imputation\n",
    "- USUALLY A BAD IDEA!\n",
    "   - MCAR: mean/median of non-missing values is the same as the mean/median of the true underlying distribution, but the variances are different\n",
    "   - not MCAR: the mean/median and the variance of the completed dataset will be off\n",
    "   - supervised ML model is too confident (MCAR) or systematically off (not MCAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3) Exclude points or features with missing values\n",
    "\n",
    "- easy to do with pandas\n",
    "- it is an ACCEPTABLE approach under two conditions:\n",
    "    - Little's test supports MCAR (p > 0.05)\n",
    "    - only small fraction of points contain missing values (maybe a few percent?)\n",
    "    - the missing values are limited to one or a few features and a large fraction of points are missing from those features (maybe up to 90%?)\n",
    "- if the MCAR assumption is justified, dropping points will not introduce biases to your model\n",
    "- due to the smaller sample size, the confidence of your model might suffer. \n",
    "- what will you do with missing values when you deploy the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(df_prep.shape)\n",
    "# by default, rows/points are dropped\n",
    "df_r = df_prep.dropna()\n",
    "print(df_r.shape)\n",
    "# drop features with missing values\n",
    "df_c = df_prep.dropna(axis=1)\n",
    "print(df_c.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Learning Objectives</font>\n",
    "\n",
    "<font color='LIGHTGRAY'>By the end of this workshop, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>Describe the three main types of missingness patterns</font>\n",
    "- <font color='LIGHTGRAY'>Evaluate simple approaches for handling missing values</font>\n",
    "- **Apply multivariate imputation**\n",
    "- <font color='LIGHTGRAY'>Apply XGBoost to a dataset with missing values</font>\n",
    "- <font color='LIGHTGRAY'>Apply the reduced-features model (also called the pattern submodel approach)</font>\n",
    "- <font color='LIGHTGRAY'>Decide which approach is best for your dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## sklearn's IterativeImputer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <font color='LIGHTGRAY'>Learning Objectives</font>\n",
    "\n",
    "<font color='LIGHTGRAY'>By the end of this workshop, you will be able to</font>\n",
    "- <font color='LIGHTGRAY'>Describe the three main types of missingness patterns</font>\n",
    "- <font color='LIGHTGRAY'>Evaluate simple approaches for handling missing values</font>\n",
    "- <font color='LIGHTGRAY'>Apply multivariate imputation</font>\n",
    "- **Apply XGBoost to a dataset with missing values**\n",
    "- <font color='LIGHTGRAY'>Apply the reduced-features model (also called the pattern submodel approach)</font>\n",
    "- <font color='LIGHTGRAY'>Decide which approach is best for your dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XGBoost and missing values\n",
    "- sklearn assumes the feature matrix (X) and the target variable (y) are complete \n",
    "- XGBoost doesn't! \n",
    "   - it runs just fine with np.nans in X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(OneHotEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
